
@Manual{R-base,
	title = {R: A Language and Environment for Statistical
			Computing},
	author = {{R Core Team}},
	organization = {R Foundation for Statistical Computing},
	address = {Vienna, Austria},
	year = {2019},
	url = {https://www.R-project.org},
}

@article{rust_sub-diffraction-limit_2006,
	title = {Sub-diffraction-limit imaging by stochastic optical reconstruction microscopy ({STORM})},
	volume = {3},
	number = {10},
	journal = {Nature methods},
	author = {Rust, Michael J. and Bates, Mark and Zhuang, Xiaowei},
	year = {2006},
	keywords = {EVE},
	pages = {793},
	file = {Snapshot:C\:\\Users\\Koen Martens\\ZoteroCustom\\storage\\H4M8C73D\\nmeth929.html:text/html},
}

@article{parthasarathy_rapid_2012,
	title = {Rapid, accurate particle tracking by calculation of radial symmetry centers},
	volume = {9},
	copyright = {© 2012 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1548-7091},
	url = {http://www.nature.com/nmeth/journal/v9/n7/full/nmeth.2071.html},
	doi = {10.1038/nmeth.2071},
	abstract = {I introduce an algorithm for subpixel localization of imaged objects based on an analytic, non-iterative calculation of the best-fit radial symmetry center. This approach yields tracking accuracies that are near theoretical limits, similarly to Gaussian fitting, but with orders-of-magnitude faster execution time, lower sensitivity to nearby particles and applicability to any radially symmetric intensity distribution. I demonstrate the method with several types of data, including super-resolution microscopy images.},
	language = {en},
	number = {7},
	urldate = {2017-02-27},
	journal = {Nature Methods},
	author = {Parthasarathy, Raghuveer},
	month = jul,
	year = {2012},
	keywords = {Biophysics, EVE, Imaging, microscopy},
	pages = {724--726},
	file = {Full Text PDF:C\:\\Users\\Koen Martens\\ZoteroCustom\\storage\\PE5TVHDU\\Parthasarathy - 2012 - Rapid, accurate particle tracking by calculation o.pdf:application/pdf;nmeth.2071-S1.pdf:C\:\\Users\\Koen Martens\\ZoteroCustom\\storage\\IS6JKH98\\nmeth.2071-S1.pdf:application/pdf;Snapshot:C\:\\Users\\Koen Martens\\ZoteroCustom\\storage\\8W8BH4B2\\nmeth.2071.html:text/html},
}

@article{betzig_imaging_2006,
	title = {Imaging intracellular fluorescent proteins at nanometer resolution},
	volume = {313},
	number = {5793},
	journal = {Science},
	author = {Betzig, Eric and Patterson, George H. and Sougrat, Rachid and Lindwasser, O. Wolf and Olenych, Scott and Bonifacino, Juan S. and Davidson, Michael W. and Lippincott-Schwartz, Jennifer and Hess, Harald F.},
	year = {2006},
	keywords = {EVE},
	pages = {1642--1645},
	file = {Fulltext:C\:\\Users\\Koen Martens\\ZoteroCustom\\storage\\8DC4SUSJ\\1642.html:text/html;Snapshot:C\:\\Users\\Koen Martens\\ZoteroCustom\\storage\\ZD2FXBYF\\1642.html:text/html},
}

@article{sharonov_wide-field_2006,
	title = {Wide-field subdiffraction imaging by accumulated binding of diffusing probes},
	volume = {103},
	copyright = {© 2006 by The National Academy of Sciences of the USA},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/103/50/18911},
	doi = {10.1073/pnas.0609643104},
	abstract = {A method is introduced for subdiffraction imaging that accumulates points by collisional flux. It is based on targeting the surface of objects by fluorescent probes diffusing in the solution. Because the flux of probes at the object is essentially constant over long time periods, the examination of an almost unlimited number of individual probe molecules becomes possible. Each probe that hits the object and that becomes immobilized is located with high precision by replacing its point-spread function by a point at its centroid. Images of lipid bilayers, contours of these bilayers, and large unilamellar vesicles are shown. A spatial resolution of ≈25 nm is readily achieved. The ability of the method to effect rapid nanoscale imaging and spatial resolution below Rayleigh criterion and without the necessity for labeling with fluorescent probes is proven.},
	language = {en},
	number = {50},
	urldate = {2019-04-29},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Sharonov, Alexey and Hochstrasser, Robin M.},
	month = dec,
	year = {2006},
	pmid = {17142314},
	keywords = {diffusion controlled, EVE, fluorescence, single molecule},
	pages = {18911--18916},
	file = {Full Text:C\:\\Users\\Koen Martens\\ZoteroCustom\\storage\\9YU784I9\\18911.html:text/html;Full Text PDF:C\:\\Users\\Koen Martens\\ZoteroCustom\\storage\\Z7KDU6GW\\Sharonov and Hochstrasser - 2006 - Wide-field subdiffraction imaging by accumulated b.pdf:application/pdf;Full Text PDF:C\:\\Users\\Koen Martens\\ZoteroCustom\\storage\\782D452W\\Sharonov and Hochstrasser - 2006 - Wide-field subdiffraction imaging by accumulated b.pdf:application/pdf;Snapshot:C\:\\Users\\Koen Martens\\ZoteroCustom\\storage\\Z8MUAK96\\18911.html:text/html;Snapshot:C\:\\Users\\Koen Martens\\ZoteroCustom\\storage\\4335Q7N9\\18911.html:text/html},
}

@article{martens_phasor_2018,
	title = {Phasor based single-molecule localization microscopy in {3D} ({pSMLM}-{3D}): {An} algorithm for {MHz} localization rates using standard {CPUs}},
	volume = {148},
	issn = {0021-9606},
	shorttitle = {Phasor based single-molecule localization microscopy in {3D} ({pSMLM}-{3D})},
	url = {https://aip.scitation.org/doi/10.1063/1.5005899},
	doi = {10.1063/1.5005899},
	abstract = {We present a fast and model-free 2D and 3D single-molecule localization algorithm that allows more than 3 × 106 localizations per second to be calculated on a standard multi-core central processing unit with localization accuracies in line with the most accurate algorithms currently available. Our algorithm converts the region of interest around a point spread function to two phase vectors (phasors) by calculating the first Fourier coefficients in both the x- and y-direction. The angles of these phasors are used to localize the center of the single fluorescent emitter, and the ratio of the magnitudes of the two phasors is a measure for astigmatism, which can be used to obtain depth information (z-direction). Our approach can be used both as a stand-alone algorithm for maximizing localization speed and as a first estimator for more time consuming iterative algorithms.},
	number = {12},
	urldate = {2018-04-10},
	journal = {The Journal of Chemical Physics},
	author = {Martens, Koen J. A. and Bader, Arjen N. and Baas, Sander and Rieger, Bernd and Hohlbein, Johannes},
	year = {2018},
	keywords = {EVE},
	pages = {123311},
	file = {2017_phasor_si_jcp_rebuttal_final_nomarkup (1).pdf:C\:\\Users\\Koen Martens\\ZoteroCustom\\storage\\BK6XNNJP\\2017_phasor_si_jcp_rebuttal_final_nomarkup (1).pdf:application/pdf;Full Text PDF:C\:\\Users\\Koen Martens\\ZoteroCustom\\storage\\WHV5KPHA\\Martens et al. - 2017 - Phasor based single-molecule localization microsco.pdf:application/pdf;Snapshot:C\:\\Users\\Koen Martens\\ZoteroCustom\\storage\\ISRABHTE\\1.html:text/html},
}

@article{endesfelder_simple_2014,
	title = {A simple method to estimate the average localization precision of a single-molecule localization microscopy experiment},
	volume = {141},
	issn = {0948-6143, 1432-119X},
	url = {http://link.springer.com/10.1007/s00418-014-1192-3},
	doi = {10.1007/s00418-014-1192-3},
	abstract = {The localization precision is a crucial and important parameter for single-molecule localization microscopy (SMLM) and directly influences the achievable spatial resolution. It primarily depends on experimental imaging conditions and the registration potency of the algorithm used. We propose a new and simple routine to estimate the average experimental localization precision in SMLM, based on the nearest neighbor analysis. By exploring different experimental and simulated targets, we show that this approach can be generally used for any 2D or 3D SMLM data and that reliable values for the localization precision σSMLM are obtained. Knowing σSMLM is a prerequisite for consistent visualization or any quantitative structural analysis, e.g., cluster analysis or colocalization studies.},
	language = {en},
	number = {6},
	urldate = {2021-03-10},
	journal = {Histochemistry and Cell Biology},
	author = {Endesfelder, Ulrike and Malkusch, Sebastian and Fricke, Franziska and Heilemann, Mike},
	month = jun,
	year = {2014},
	keywords = {EVE},
	pages = {629--638},
	file = {Endesfelder et al. - 2014 - A simple method to estimate the average localizati.pdf:C\:\\Users\\Koen Martens\\ZoteroCustom\\storage\\PLSQVBTL\\Endesfelder et al. - 2014 - A simple method to estimate the average localizati.pdf:application/pdf},
}

@techreport{cabriel_event-based_2022,
	type = {preprint},
	title = {Event-based vision sensor enables fast and dense single-molecule localization microscopy},
	url = {http://biorxiv.org/lookup/doi/10.1101/2022.07.22.501162},
	abstract = {Single-molecule localization microscopy (SMLM) applications are often hampered by the fixed frame rate at which data acquisition is performed. Here, we present an alternative new approach of acquiring and processing SMLM data based on an event-based (or neuromorphic vision) sensor. This type of sensor reacts to light intensity changes rather than integrating the number of photons during each frame exposure time. This makes them particularly suited to SMLM, where the ability to surpass the diffraction-limited resolution is provided by blinking events. Each pixel works independently and returns a signal only when an intensity change is detected; intensity changes are returned as a list with pixel positions and timestamps rather than frames with a fixed frame rate. Since the output is a sparse list containing only useful data (for example a molecule turning on or off), the temporal resolution is significantly faster than typical speeds of EMCCD and sCMOS cameras. Here we demonstrate the feasibility of SMLM super-resolution imaging with this type of event-based sensors which, in addition, are more affordable than EMCCD or sCMOS cameras. We characterize the localization precision and show that it is equivalent to that of frame-based scientific cameras, including on fluorescently labelled biological samples. Furthermore, taking advantage of the unique properties of the sensor, we use event-based SMLM to perform very dense single-molecule acquisitions, where frame-based cameras experience significant limitations. All the data processing codes are made available.},
	language = {en},
	urldate = {2022-07-25},
	institution = {Biophysics},
	author = {Cabriel, Clement and Specht, Christian G and Izeddin, Ignacio},
	month = jul,
	year = {2022},
	doi = {10.1101/2022.07.22.501162},
	keywords = {EVE},
	file = {Cabriel et al. - 2022 - Event-based vision sensor enables fast and dense s.pdf:C\:\\Users\\Koen Martens\\ZoteroCustom\\storage\\GI89ZW7L\\Cabriel et al. - 2022 - Event-based vision sensor enables fast and dense s.pdf:application/pdf},
}

@article{lin_eigen-feature_2014,
	title = {Eigen-feature analysis of weighted covariance matrices for {LiDAR} point cloud classification},
	volume = {94},
	issn = {0924-2716},
	url = {https://www.sciencedirect.com/science/article/pii/S0924271614001117},
	doi = {10.1016/j.isprsjprs.2014.04.016},
	abstract = {The features used in the separation of different objects are important for successful point cloud classification. Eigen-features from a covariance matrix of a point set with the sample mean are commonly used geometric features that can describe the local geometric characteristics of a point cloud and indicate whether the local geometry is linear, planar, or spherical. However, eigen-features calculated by the principal component analysis of a covariance matrix are sensitive to LiDAR data with inherent noise and incomplete shapes because of the non-robust statistical analysis. To obtain reliable eigen-features from LiDAR data and to improve classification accuracy, we introduce a method of analyzing local geometric characteristics of a point cloud by using a weighted covariance matrix with a geometric median. Each point is assigned a weight to represent its spatial contribution in the weighted principal component analysis and to estimate the geometric median which can be regarded as a localized center of a shape. In the experiments, qualitative and quantitative analyses on airborne LiDAR data and simulated point clouds show a clear improvement of the proposed method compared with the standard eigen-features. The classification accuracy is improved by 1.6–4.5\% using a supervised classifier.},
	urldate = {2024-04-25},
	journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
	author = {Lin, Chao-Hung and Chen, Jyun-Yuan and Su, Po-Lin and Chen, Chung-Hao},
	month = aug,
	year = {2014},
	keywords = {Eigen-feature, EVE, Point cloud classification, Weighted covariance matrix},
	pages = {70--79},
	file = {ScienceDirect Snapshot:C\:\\Users\\Koen Martens\\ZoteroCustom\\storage\\KHL5BV6C\\S0924271614001117.html:text/html},
}

@inproceedings{zhong_intrinsic_2009,
	title = {Intrinsic shape signatures: {A} shape descriptor for {3D} object recognition},
	shorttitle = {Intrinsic shape signatures},
	url = {https://ieeexplore.ieee.org/document/5457637},
	doi = {10.1109/ICCVW.2009.5457637},
	abstract = {This paper presents a new approach for recognition of 3D objects that are represented as 3D point clouds. We introduce a new 3D shape descriptor called Intrinsic Shape Signature (ISS) to characterize a local/semi-local region of a point cloud. An intrinsic shape signature uses a view-independent representation of the 3D shape to match shape patches from different views directly, and a view-dependent transform encoding the viewing geometry to facilitate fast pose estimation. In addition, we present a highly efficient indexing scheme for the high dimensional ISS shape descriptors, allowing for fast and accurate search of large model databases. We evaluate the performance of the proposed algorithm on a very challenging task of recognizing different vehicle types using a database of 72 models in the presence of sensor noise, obscuration and scene clutter.},
	urldate = {2024-04-25},
	booktitle = {2009 {IEEE} 12th {International} {Conference} on {Computer} {Vision} {Workshops}, {ICCV} {Workshops}},
	author = {Zhong, Yu},
	month = sep,
	year = {2009},
	keywords = {Clouds, Encoding, EVE, Geometry, Indexing, Layout, Noise shaping, Object recognition, Shape, Spatial databases, Vehicles},
	pages = {689--696},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Koen Martens\\ZoteroCustom\\storage\\WYKTPBMW\\5457637.html:text/html},
}

@inproceedings{ng_spectral_2001,
	title = {On {Spectral} {Clustering}: {Analysis} and an algorithm},
	volume = {14},
	shorttitle = {On {Spectral} {Clustering}},
	url = {https://papers.nips.cc/paper_files/paper/2001/hash/801272ee79cfde7fa5960571fee36b9b-Abstract.html},
	abstract = {Despite many empirical successes of spectral  clustering  methods(cid:173) algorithms  that  cluster  points  using  eigenvectors  of  matrices  de(cid:173) rived  from  the  data- there  are  several  unresolved  issues.  First,  there  are  a  wide  variety  of  algorithms  that  use  the  eigenvectors  in  slightly  different  ways.  Second,  many of these  algorithms  have  no  proof that  they  will  actually  compute  a  reasonable  clustering.  In  this  paper,  we  present  a  simple  spectral  clustering  algorithm  that can be implemented using a  few  lines  of Matlab.  Using  tools  from  matrix  perturbation  theory,  we  analyze  the  algorithm,  and  give  conditions  under  which  it  can  be  expected  to  do  well.  We  also  show  surprisingly  good  experimental  results  on  a  number  of  challenging clustering problems.},
	urldate = {2024-04-25},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {MIT Press},
	author = {Ng, Andrew and Jordan, Michael and Weiss, Yair},
	year = {2001},
	keywords = {EVE},
	file = {Full Text PDF:C\:\\Users\\Koen Martens\\ZoteroCustom\\storage\\AESK3HEF\\Ng et al. - 2001 - On Spectral Clustering Analysis and an algorithm.pdf:application/pdf},
}

@article{demantke_dimensionality_2012,
	title = {{DIMENSIONALITY} {BASED} {SCALE} {SELECTION} {IN} {3D} {LIDAR} {POINT} {CLOUDS}},
	volume = {XXXVIII-5-W12},
	issn = {1682-1750},
	url = {https://isprs-archives.copernicus.org/articles/XXXVIII-5-W12/97/2011/},
	doi = {10.5194/isprsarchives-XXXVIII-5-W12-97-2011},
	abstract = {This papers presents a multi-scale method that computes robust geometric features on lidar point clouds in order to retrieve the optimal neighborhood size for each point. Three dimensionality features are calculated on spherical neighborhoods at various radius sizes. Based on combinations of the eigenvalues of the local structure tensor, they describe the shape of the neighborhood, indicating whether the local geometry is more linear (1D), planar (2D) or volumetric (3D). Two radius-selection criteria have been tested and compared for ﬁnding automatically the optimal neighborhood radius for each point. Besides, such procedure allows a dimensionality labelling, giving signiﬁcant hints for classiﬁcation and segmentation purposes. The method is successfully applied to 3D point clouds from airborne, terrestrial, and mobile mapping systems since no a priori knowledge on the distribution of the 3D points is required. Extracted dimensionality features and labellings are then favorably compared to those computed from constant size neighborhoods.},
	language = {English},
	urldate = {2024-04-25},
	journal = {The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
	author = {Demantké, J. and Mallet, C. and David, N. and Vallet, B.},
	month = sep,
	year = {2012},
	note = {Conference Name: WG V/3, I/3, I/2, III/2, III/4, VII/7, V/1{\textless}br/{\textgreater}ISPRS Workshop Laser Scanning 2011 (Volume XXXVIII-5/W12) - 29\&ndash;31 August, Calgary, Canada
Publisher: Copernicus GmbH},
	keywords = {adaptive neighborhood, dimensionality, eigenvalues, EVE, feature, multi-scale analysis, PCA, point cloud, scale selection},
	pages = {97--102},
	file = {Full Text PDF:C\:\\Users\\Koen Martens\\ZoteroCustom\\storage\\62DUZPJ2\\Demantké et al. - 2012 - DIMENSIONALITY BASED SCALE SELECTION IN 3D LIDAR P.pdf:application/pdf},
}

@article{izeddin_wavelet_2012,
	title = {Wavelet analysis for single molecule localization microscopy},
	volume = {20},
	copyright = {© 2012 OSA},
	issn = {1094-4087},
	url = {https://opg.optica.org/oe/abstract.cfm?uri=oe-20-3-2081},
	doi = {10.1364/OE.20.002081},
	abstract = {Localization of single molecules in microscopy images is a key step in quantitative single particle data analysis. Among them, single molecule based super-resolution optical microscopy techniques require high localization accuracy as well as computation of large data sets in the order of 105 single molecule detections to reconstruct a single image. We hereby present an algorithm based on image wavelet segmentation and single particle centroid determination, and compare its performance with the commonly used Gaussian fitting of the point spread function. We performed realistic simulations at different signal-to-noise ratios and particle densities and show that the calculation time using the wavelet approach can be more than one order of magnitude faster than that of Gaussian fitting without a significant degradation of the localization accuracy, from 1 nm to 4 nm in our range of study. We propose a simulation-based estimate of the resolution of an experimental single molecule acquisition.},
	language = {EN},
	number = {3},
	urldate = {2024-05-31},
	journal = {Optics Express},
	author = {Izeddin, I. and Boulanger, J. and Racine, V. and Specht, C. G. and Kechkar, A. and Nair, D. and Triller, A. and Choquet, D. and Dahan, M. and Sibarita, J. B.},
	month = jan,
	year = {2012},
	note = {Publisher: Optica Publishing Group},
	keywords = {Diffraction limit, EVE, Imaging systems, Imaging techniques, Optical microscopy, Optical systems, Total internal reflection},
	pages = {2081--2095},
	file = {Full Text PDF:C\:\\Users\\Koen Martens\\ZoteroCustom\\storage\\WNFH4WEL\\Izeddin et al. - 2012 - Wavelet analysis for single molecule localization .pdf:application/pdf},
}

@article{mangalwedhekar_achieving_2023,
	title = {Achieving nanoscale precision using neuromorphic localization microscopy},
	volume = {18},
	issn = {1748-3395},
	doi = {10.1038/s41565-022-01291-1},
	abstract = {Neuromorphic cameras are a new class of dynamic-vision-inspired sensors that encode the rate of change of intensity as events. They can asynchronously record intensity changes as spikes, independent of the other pixels in the receptive field, resulting in sparse measurements. This recording of such sparse events makes them ideal for imaging dynamic processes, such as the stochastic emission of isolated single molecules. Here we show the application of neuromorphic detection to localize nanoscale fluorescent objects below the diffraction limit, with a precision below 20 nm. We demonstrate a combination of neuromorphic detection with segmentation and deep learning approaches to localize and track fluorescent particles below 50 nm with millisecond temporal resolution. Furthermore, we show that combining information from events resulting from the rate of change of intensities improves the classical limit of centroid estimation of single fluorescent objects by nearly a factor of two. Additionally, we validate that using post-processed data from the neuromorphic detector at defined windows of temporal integration allows a better evaluation of the fractalized diffusion of single particle trajectories. Our observations and analysis is useful for event sensing by nonlinear neuromorphic devices to ameliorate real-time particle localization approaches at the nanoscale.},
	language = {eng},
	number = {4},
	journal = {Nature Nanotechnology},
	author = {Mangalwedhekar, Rohit and Singh, Nivedita and Thakur, Chetan Singh and Seelamantula, Chandra Sekhar and Jose, Mini and Nair, Deepak},
	month = apr,
	year = {2023},
	pmid = {36690737},
	keywords = {EVE},
	pages = {380--389},
}

@article{heilemann_subdiffraction-resolution_2008,
	title = {Subdiffraction-{Resolution} {Fluorescence} {Imaging} with {Conventional} {Fluorescent} {Probes}},
	volume = {47},
	copyright = {Copyright © 2008 WILEY-VCH Verlag GmbH \& Co. KGaA, Weinheim},
	issn = {1521-3773},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/anie.200802376},
	doi = {10.1002/anie.200802376},
	abstract = {Eagle eyes: dSTORM uses conventional photoswitchable fluorescent dyes that can be reversibly cycled between a fluorescent and a dark state by irradiation with light of different wavelengths (see picture). This elegant approach can visualize cellular structures with a resolution of approximately 20 nm, far beyond the diffraction limit of light, without the need of an activator molecule.},
	number = {33},
	urldate = {2024-08-01},
	journal = {Angewandte Chemie International Edition},
	author = {Heilemann, Mike and van de Linde, Sebastian and Schüttpelz, Mark and Kasper, Robert and Seefeldt, Britta and Mukherjee, Anindita and Tinnefeld, Philip and Sauer, Markus},
	year = {2008},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/anie.200802376},
	keywords = {EVE, fluorescent probes, imaging agents, localization microscopy, optical switches, subdiffraction resolution},
	pages = {6172--6176},
	file = {Full Text PDF:C\:\\Users\\Koen Martens\\ZoteroCustom\\storage\\J8YXUQDB\\Heilemann et al. - 2008 - Subdiffraction-Resolution Fluorescence Imaging wit.pdf:application/pdf;Snapshot:C\:\\Users\\Koen Martens\\ZoteroCustom\\storage\\PRGN78H4\\anie.html:text/html},
}

@article{stallinga_accuracy_2010,
	title = {Accuracy of the {Gaussian} {Point} {Spread} {Function} model in {2D} localization microscopy},
	volume = {18},
	copyright = {© 2010 OSA},
	issn = {1094-4087},
	url = {https://opg.optica.org/oe/abstract.cfm?uri=oe-18-24-24461},
	doi = {10.1364/OE.18.024461},
	abstract = {The Gaussian function is simple and easy to implement as Point Spread Function (PSF) model for fitting the position of fluorescent emitters in localization microscopy. Despite its attractiveness the appropriateness of the Gaussian is questionable as it is not based on the laws of optics. Here we study the effect of emission dipole orientation in conjunction with optical aberrations on the localization accuracy of position estimators based on a Gaussian model PSF. Simulated image spots, calculated with all effects of high numerical aperture, interfaces between media, polarization, dipole orientation and aberrations taken into account, were fitted with a Gaussian PSF based Maximum Likelihood Estimator. For freely rotating dipole emitters it is found that the Gaussian works fine. The same, theoretically optimum, localization accuracy is found as if the true PSF were a Gaussian, even for aberrations within the usual tolerance limit of high-end optical imaging systems such as microscopes (Marechal’s diffraction limit). For emitters with a fixed dipole orientation this is not the case. Localization errors are found that reach up to 40 nm for typical system parameters and aberration levels at the diffraction limit. These are systematic errors that are independent of the total photon count in the image. The Gaussian function is therefore inappropriate, and more sophisticated PSF models are a practical necessity.},
	language = {EN},
	number = {24},
	urldate = {2024-08-01},
	journal = {Optics Express},
	author = {Stallinga, Sjoerd and Rieger, Bernd},
	month = nov,
	year = {2010},
	note = {Publisher: Optica Publishing Group},
	keywords = {Diffraction limit, EVE, Imaging systems, Optical aberration, Optical imaging, Optical systems, Total internal reflection},
	pages = {24461--24476},
	file = {Full Text PDF:C\:\\Users\\Koen Martens\\ZoteroCustom\\storage\\TGXQ2JQF\\Stallinga and Rieger - 2010 - Accuracy of the Gaussian Point Spread Function mod.pdf:application/pdf},
}

@article{mortensen_optimized_2010,
	title = {Optimized localization analysis for single-molecule tracking and super-resolution microscopy},
	volume = {7},
	copyright = {2010 Springer Nature America, Inc.},
	issn = {1548-7105},
	url = {https://www.nature.com/articles/nmeth.1447},
	doi = {10.1038/nmeth.1447},
	abstract = {A theoretical and experimental treatment of fitting methods for localizing the centers of diffraction-limited spots is presented. Use of an analytical point spread function shows that maximum likelihood fitting is superior to both unweighted and weighted least squares Gaussian fitting.},
	language = {en},
	number = {5},
	urldate = {2024-08-01},
	journal = {Nature Methods},
	author = {Mortensen, Kim I. and Churchman, L. Stirling and Spudich, James A. and Flyvbjerg, Henrik},
	month = may,
	year = {2010},
	note = {Publisher: Nature Publishing Group},
	keywords = {EVE, Super-resolution microscopy},
	pages = {377--381},
	file = {Full Text PDF:C\:\\Users\\Koen Martens\\ZoteroCustom\\storage\\B44VUGVW\\Mortensen et al. - 2010 - Optimized localization analysis for single-molecul.pdf:application/pdf},
}

@article{martens_raw_2022,
	title = {Raw {Data} to {Results}: {A} {Hands}-{On} {Introduction} and {Overview} of {Computational} {Analysis} for {Single}-{Molecule} {Localization} {Microscopy}},
	volume = {1},
	issn = {2673-7647},
	shorttitle = {Raw {Data} to {Results}},
	url = {https://www.frontiersin.org/article/10.3389/fbinf.2021.817254},
	abstract = {Single-molecule localization microscopy (SMLM) is an advanced microscopy method that uses the blinking of fluorescent molecules to determine the position of these molecules with a resolution below the diffraction limit (5–40 nm). While SMLM imaging itself is becoming more popular, the computational analysis surrounding the technique is still a specialized area and often remains a “black box” for experimental researchers. Here, we provide an introduction to the required computational analysis of SMLM imaging, post-processing and typical data analysis. Importantly, user-friendly, ready-to-use and well-documented code in Python and MATLAB with exemplary data is provided as an interactive experience for the reader, as well as a starting point for further analysis. Our code is supplemented by descriptions of the computational problems and their implementation. We discuss the state of the art in computational methods and software suites used in SMLM imaging and data analysis. Finally, we give an outlook into further computational challenges in the field.},
	urldate = {2022-05-09},
	journal = {Frontiers in Bioinformatics},
	author = {Martens, Koen J. A. and Turkowyd, Bartosz and Endesfelder, Ulrike},
	year = {2022},
	keywords = {EVE},
	file = {Full Text PDF:C\:\\Users\\Koen Martens\\ZoteroCustom\\storage\\6J7KB8LR\\Martens et al. - 2022 - Raw Data to Results A Hands-On Introduction and O.pdf:application/pdf},
}

@article{huang_three-dimensional_2008,
	title = {Three-{Dimensional} {Super}-{Resolution} {Imaging} by {Stochastic} {Optical} {Reconstruction} {Microscopy}},
	volume = {319},
	issn = {0036-8075},
	url = {http://www.jstor.org/stable/20053326},
	abstract = {Recent advances in far-field fluorescence microscopy have led to substantial improvements in image resolution, achieving a near-molecular resolution of 20 to 30 nanometers in the two lateral dimensions. Three-dimensional (3D) nanoscale-resolution imaging, however, remains a challenge. We demonstrated 3D stochastic optical reconstruction microscopy (STORM) by using optical astigmatism to determine both axial and lateral positions of individual fluorophores with nanometer accuracy. Iterative, stochastic activation of photoswitchable probes enables high-precision 3D localization of each probe, and thus the construction of a 3D image, without scanning the sample. Using this approach, we achieved an image resolution of 20 to 30 nanometers in the lateral dimensions and 50 to 60 nanometers in the axial dimension. This development allowed us to resolve the 3D morphology of nanoscopic cellular structures.},
	number = {5864},
	urldate = {2016-09-27},
	journal = {Science},
	author = {Huang, Bo and Wang, Wenqin and Bates, Mark and Zhuang, Xiaowei},
	year = {2008},
	keywords = {Super-resolution microscopy, 3-D reconstruction, EVE},
	pages = {810--813},
	file = {Full Text PDF:C\:\\Users\\Koen Martens\\ZoteroCustom\\storage\\95X9E7EN\\Huang et al. - 2008 - Three-Dimensional Super-Resolution Imaging by Stoc.pdf:application/pdf;Full Text PDF:C\:\\Users\\Koen Martens\\ZoteroCustom\\storage\\5CBQ638S\\Huang et al. - 2008 - Three-Dimensional Super-Resolution Imaging by Stoc.pdf:application/pdf;JSTOR Full Text PDF:C\:\\Users\\Koen Martens\\ZoteroCustom\\storage\\F859DXGA\\Huang et al. - 2008 - Three-Dimensional Super-Resolution Imaging by Stoc.pdf:application/pdf;NIHMS88401-supplement-1.pdf:C\:\\Users\\Koen Martens\\ZoteroCustom\\storage\\3VE7TTM9\\NIHMS88401-supplement-1.pdf:application/pdf;Snapshot:C\:\\Users\\Koen Martens\\ZoteroCustom\\storage\\NIVMQDQC\\810.html:text/html;Snapshot:C\:\\Users\\Koen Martens\\ZoteroCustom\\storage\\7N9SCZC6\\810.html:text/html},
}

@article{cnossen_drift_2021,
	title = {Drift correction in localization microscopy using entropy minimization},
	volume = {29},
	copyright = {© 2021 Optical Society of America},
	issn = {1094-4087},
	url = {https://opg.optica.org/oe/abstract.cfm?uri=oe-29-18-27961},
	doi = {10.1364/OE.426620},
	abstract = {Localization microscopy offers resolutions down to a single nanometer but currently requires additional dedicated hardware or fiducial markers to reduce resolution loss from the drift of the sample. Drift estimation without fiducial markers is typically implemented using redundant cross correlation (RCC). We show that RCC has sub-optimal precision and bias, which leaves room for improvement. Here, we minimize a bound on the entropy of the obtained localizations to efficiently compute a precise drift estimate. Within practical compute-time constraints, simulations show a 5x improvement in drift estimation precision over the widely used RCC algorithm. The algorithm operates directly on fluorophore localizations and is tested on simulated and experimental datasets in 2D and 3D. An open source implementation is provided, implemented in Python and C++, and can utilize a GPU if available.},
	language = {EN},
	number = {18},
	urldate = {2024-08-02},
	journal = {Optics Express},
	author = {Cnossen, Jelmer and Cui, Tao Ju and Joo, Chirlmin and Smith, Carlas},
	month = aug,
	year = {2021},
	note = {Publisher: Optica Publishing Group},
	keywords = {Diffraction limit, Image quality, Image resolution, Optical microscopy, EVE, Camera calibration, Super resolution imaging},
	pages = {27961--27974},
	file = {Full Text PDF:C\:\\Users\\Koen Martens\\ZoteroCustom\\storage\\QFXNNM9E\\Cnossen et al. - 2021 - Drift correction in localization microscopy using .pdf:application/pdf},
}
